"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[693],{3889:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>a,contentTitle:()=>l,default:()=>p,frontMatter:()=>o,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"sbi-pipeline/sbi-pipeline","title":"SBI Pipeline","description":"This section provides an overview of the Simulation-Based Inference (SBI) pipeline used to estimate posterior distributions in the absence of tractable likelihood functions. The pipeline leverages forward simulations and neural density estimation to perform efficient, scalable inference.","source":"@site/docs/sbi-pipeline/001-sbi-pipeline.md","sourceDirName":"sbi-pipeline","slug":"/sbi-pipeline/sbi-pipeline","permalink":"/likelihood-free-inference/sbi-pipeline/sbi-pipeline","draft":false,"unlisted":false,"editUrl":"https://github.com/role-model/likelihood-free-inference/docs/sbi-pipeline/001-sbi-pipeline.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"sbi-pipeline","title":"SBI Pipeline","sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"SBI Pipeline","permalink":"/likelihood-free-inference/category/sbi-pipeline"},"next":{"title":"Neural Posterior Estimation","permalink":"/likelihood-free-inference/category/neural-posterior-estimation"}}');var t=n(4848),s=n(8453);const o={id:"sbi-pipeline",title:"SBI Pipeline",sidebar_position:1},l="SBI Pipeline",a={},d=[{value:"Overview",id:"overview",level:2},{value:"Pipeline Components",id:"pipeline-components",level:2},{value:"1. Prior Distribution",id:"1-prior-distribution",level:3},{value:"2. Simulator",id:"2-simulator",level:3},{value:"3. Observation",id:"3-observation",level:3},{value:"4. Inference Method",id:"4-inference-method",level:3},{value:"Training",id:"training",level:2},{value:"Posterior Sampling",id:"posterior-sampling",level:2},{value:"Summary",id:"summary",level:2}];function c(e){const i={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.header,{children:(0,t.jsx)(i.h1,{id:"sbi-pipeline",children:"SBI Pipeline"})}),"\n",(0,t.jsx)(i.p,{children:"This section provides an overview of the Simulation-Based Inference (SBI) pipeline used to estimate posterior distributions in the absence of tractable likelihood functions. The pipeline leverages forward simulations and neural density estimation to perform efficient, scalable inference."}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"overview",children:"Overview"}),"\n",(0,t.jsx)(i.p,{children:"SBI is designed to perform inference in cases where traditional likelihood-based methods (e.g., MCMC, variational inference) are infeasible due to the complexity or inaccessibility of the likelihood function. Instead, it operates by:"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsx)(i.li,{children:"Sampling from a prior distribution"}),"\n",(0,t.jsx)(i.li,{children:"Simulating observations using a domain-specific simulator"}),"\n",(0,t.jsx)(i.li,{children:"Comparing simulated data to observed data"}),"\n",(0,t.jsx)(i.li,{children:"Learning a posterior using neural networks"}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"The pipeline is modular and can be extended with different prior types, simulators, summary statistics, and inference algorithms."}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"pipeline-components",children:"Pipeline Components"}),"\n",(0,t.jsx)(i.p,{children:"The diagram below illustrates the full SBI pipeline, from sampling the prior and simulating data, to generating a dataset and training a posterior model."}),"\n",(0,t.jsx)(i.p,{children:(0,t.jsx)(i.img,{alt:"SBI Workflow Diagram",src:n(9059).A+"",width:"1920",height:"1080"})}),"\n",(0,t.jsx)(i.h3,{id:"1-prior-distribution",children:"1. Prior Distribution"}),"\n",(0,t.jsxs)(i.p,{children:["The pipeline begins by defining a prior over the parameters of interest. This can be a uniform or normal distribution, often implemented via ",(0,t.jsx)(i.code,{children:"sbi.utils.BoxUniform"})," or ",(0,t.jsx)(i.code,{children:"torch.distributions"}),"."]}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:"prior = sbi.utils.BoxUniform(low=torch.tensor([...]), high=torch.tensor([...]))\n"})}),"\n",(0,t.jsx)(i.h3,{id:"2-simulator",children:"2. Simulator"}),"\n",(0,t.jsx)(i.p,{children:"A simulator function maps parameters to synthetic observations. It must be deterministic or stochastic and compatible with PyTorch tensors."}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:"def simulator(theta):\n    # Run your model and return simulated data\n    return simulate_model(theta)\n"})}),"\n",(0,t.jsx)(i.p,{children:"Simulators can be CPU- or GPU-based, and should ideally be vectorized for performance."}),"\n",(0,t.jsx)(i.h3,{id:"3-observation",children:"3. Observation"}),"\n",(0,t.jsx)(i.p,{children:"This is the real or reference dataset for which we want to estimate the posterior distribution over parameters."}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:"x_o = torch.tensor([...])  # Observed data\n"})}),"\n",(0,t.jsx)(i.p,{children:"The observation must match the output format of the simulator."}),"\n",(0,t.jsx)(i.h3,{id:"4-inference-method",children:"4. Inference Method"}),"\n",(0,t.jsx)(i.p,{children:"The sbi library provides multiple inference methods, such as:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"SNPE (Sequential Neural Posterior Estimation)"}),"\n",(0,t.jsx)(i.li,{children:"SNLE (Likelihood Estimation)"}),"\n",(0,t.jsx)(i.li,{children:"SNRE (Ratio Estimation)"}),"\n"]}),"\n",(0,t.jsx)(i.p,{children:"A common pattern is:"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:"inference = sbi.inference.SNPE(prior=prior)\ndensity_estimator = inference.append_simulations(theta, x).train()\nposterior = inference.build_posterior(density_estimator)\n"})}),"\n",(0,t.jsx)(i.h2,{id:"training",children:"Training"}),"\n",(0,t.jsxs)(i.p,{children:["The neural density estimator is trained using simulated data (",(0,t.jsx)(i.code,{children:"theta"}),", ",(0,t.jsx)(i.code,{children:"x"}),") pairs. Training typically takes place on GPU and supports checkpointing/logging."]}),"\n",(0,t.jsx)(i.h2,{id:"posterior-sampling",children:"Posterior Sampling"}),"\n",(0,t.jsx)(i.p,{children:"After training, the posterior can be sampled conditionally on the observed data:"}),"\n",(0,t.jsx)(i.pre,{children:(0,t.jsx)(i.code,{className:"language-python",children:"samples = posterior.sample((1000,), x=x_o)\n"})}),"\n",(0,t.jsx)(i.p,{children:"These samples represent the posterior distribution over parameters given the observed data."}),"\n",(0,t.jsx)(i.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(i.p,{children:"The SBI pipeline enables flexible, modular, and scalable inference workflows. It is particularly useful for problems involving:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Custom simulators"}),"\n",(0,t.jsx)(i.li,{children:"Complex, high-dimensional data"}),"\n",(0,t.jsx)(i.li,{children:"Scientific models with uncertain or implicit likelihoods"}),"\n",(0,t.jsx)(i.li,{children:"Subsequent sections provide details on neural posterior estimation, performance tuning, and full end-to-end examples."}),"\n"]})]})}function p(e={}){const{wrapper:i}={...(0,s.R)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,i,n)=>{n.d(i,{R:()=>o,x:()=>l});var r=n(6540);const t={},s=r.createContext(t);function o(e){const i=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function l(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),r.createElement(s.Provider,{value:i},e.children)}},9059:(e,i,n)=>{n.d(i,{A:()=>r});const r=n.p+"assets/images/flowchart-fe1f11be04f1065f0d81ab14bfad9d60.png"}}]);