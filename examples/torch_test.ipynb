{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Any, List\n",
    "\n",
    "class Distribution(ABC):\n",
    "    def __init__(self, low: float, high: float):\n",
    "        if not isinstance(low, (int, float)) or not isinstance(high, (int, float)):\n",
    "            raise TypeError(\"low and high must be numeric (int or float)\")\n",
    "        if low >= high:\n",
    "            raise ValueError(\"low must be less than high\")\n",
    "\n",
    "        self.low = float(low)\n",
    "        self.high = float(high)\n",
    "\n",
    "    @abstractmethod\n",
    "    def discretize(self, n: float) -> Any:\n",
    "        return n\n",
    "\n",
    "\n",
    "class FloatDistribution(Distribution):\n",
    "    def __init__(self, low: float, high: float):\n",
    "        super().__init__(low, high)\n",
    "\n",
    "    def discretize(self, n: float) -> float:\n",
    "        return n\n",
    "\n",
    "\n",
    "class IntDistribution(Distribution):\n",
    "    def __init__(self, low: int, high: int):\n",
    "        super().__init__(float(low), float(high))  # Call super with floats\n",
    "\n",
    "    def discretize(self, n: float) -> int:\n",
    "        return round(n)\n",
    "\n",
    "\n",
    "class ChoiceDistribution(Distribution):\n",
    "    def __init__(self, choices: List[Any]):\n",
    "        self.choices = choices\n",
    "        super().__init__(0, len(choices) - 1)\n",
    "\n",
    "    def discretize(self, n: float) -> Any:\n",
    "        return self.choices[round(n)]\n",
    "\n",
    "# human readable prior\n",
    "from dataclasses import dataclass, fields\n",
    "from torch.distributions import Uniform\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class ModelParams:\n",
    "    individuals_local: int\n",
    "    individuals_meta: int\n",
    "    species_meta: int\n",
    "    speciation_local: float\n",
    "    speciation_meta: float\n",
    "    extinction_meta: float\n",
    "    env_sigma: float\n",
    "    trait_sigma: float\n",
    "    comp_sigma: float\n",
    "    dispersal_prob: float\n",
    "    mutation_rate: float\n",
    "    equilib_escape: float\n",
    "    num_basepairs: int\n",
    "    init_type: str\n",
    "    niter: int\n",
    "    niterTimestep: int\n",
    "\n",
    "@dataclass\n",
    "class ModelPrior:\n",
    "    individuals_local: int | IntDistribution\n",
    "    individuals_meta: int | IntDistribution\n",
    "    species_meta: int | IntDistribution\n",
    "    speciation_local: float | FloatDistribution\n",
    "    speciation_meta: float | FloatDistribution\n",
    "    extinction_meta: float | FloatDistribution\n",
    "    env_sigma: float | FloatDistribution\n",
    "    trait_sigma: float | FloatDistribution\n",
    "    comp_sigma: float | FloatDistribution\n",
    "    dispersal_prob: float | FloatDistribution\n",
    "    mutation_rate: float | FloatDistribution\n",
    "    equilib_escape: float | FloatDistribution\n",
    "    num_basepairs: int | IntDistribution\n",
    "    init_type: str | ChoiceDistribution\n",
    "    niter: int\n",
    "    niterTimestep: int\n",
    "    \n",
    "    def get_joint_uniform(self) -> Uniform:\n",
    "        low = []\n",
    "        high = []\n",
    "        for field in fields(self):\n",
    "            val = getattr(self, field.name)\n",
    "            if isinstance(val, Distribution):\n",
    "                low.append(val.low)\n",
    "                high.append(val.high)\n",
    "        \n",
    "        return Uniform(low=torch.tensor(low), high=torch.tensor(high))\n",
    "    \n",
    "    def get_params_from_sample(self, sample: torch.Tensor) -> ModelParams:\n",
    "        sampled_params = {}\n",
    "        sample_index = 0\n",
    "        for field_obj in fields(self):\n",
    "            value = getattr(self, field_obj.name)\n",
    "            if isinstance(value, Distribution):\n",
    "                sampled_value = sample[sample_index].item()\n",
    "                sampled_params[field_obj.name] = value.discretize(sampled_value)\n",
    "                sample_index += 1\n",
    "            else:\n",
    "                sampled_params[field_obj.name] = value\n",
    "        return ModelParams(**sampled_params)\n",
    "\n",
    "prior = ModelPrior(\n",
    "    individuals_local=IntDistribution(50, 300),\n",
    "    individuals_meta=IntDistribution(400, 1000),\n",
    "    species_meta=50,\n",
    "    speciation_local=0.05,\n",
    "    speciation_meta=0.05,\n",
    "    extinction_meta=0.05,\n",
    "    env_sigma=0.5,\n",
    "    trait_sigma=1,\n",
    "    comp_sigma=0.5,\n",
    "    dispersal_prob=0.1,\n",
    "    mutation_rate=0.01,\n",
    "    equilib_escape=1,\n",
    "    num_basepairs=250,\n",
    "    init_type='oceanic_island',\n",
    "    niter=2000,\n",
    "    niterTimestep=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using GitHub PAT from the git credential store.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing the 'roleR' R package from GitHub...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Skipping install of 'roleR' from a github remote, the SHA1 (cc6546a1) has not changed since last install.\n",
      "  Use `force = TRUE` to force installation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "# Import necessary modules\n",
    "try:\n",
    "    import rpy2.robjects as robjects\n",
    "    from rpy2.robjects.packages import importr\n",
    "    from rpy2.robjects import pandas2ri\n",
    "except ImportError as e:\n",
    "    raise ImportError(\n",
    "        \"The 'rpy2' library is required but not installed. \"\n",
    "        \"Install it with 'pip install rpy2'.\"\n",
    "    ) from e\n",
    "    \n",
    "# Activate pandas conversion for rpy2\n",
    "pandas2ri.activate()\n",
    "\n",
    "\n",
    "# Install R packages if they are not already installed\n",
    "try:\n",
    "    remotes = importr('remotes')\n",
    "    print(\"Installing the 'roleR' R package from GitHub...\")\n",
    "    remotes.install_github(\"role-model/roleR\", dependencies=True)\n",
    "except Exception as e:\n",
    "    warnings.warn(\n",
    "        f\"Error installing R packages: {e}\\n\"\n",
    "        \"Make sure you have R and the 'remotes' package installed correctly.\",\n",
    "        RuntimeWarning\n",
    "    )\n",
    "\n",
    "# Import the R package\n",
    "try:\n",
    "    roleR = importr('roleR')\n",
    "except Exception as e:\n",
    "    raise ImportError(\n",
    "        f\"Error importing the 'roleR' R package: {e}\\n\"\n",
    "        \"Ensure the package is installed and available in your R environment.\"\n",
    "    ) from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "import numpy as np\n",
    "\n",
    "class Simulator:\n",
    "    def __init__(self, prior: ModelPrior, columns: list[str]):\n",
    "        self.prior = prior\n",
    "        self.columns = columns\n",
    "    \n",
    "    def simulate(self, theta: torch.Tensor) -> torch.Tensor:\n",
    "        arr = []\n",
    "        for t in theta:\n",
    "            params = self.prior.get_params_from_sample(t)\n",
    "            params = asdict(params)\n",
    "            p = roleR.roleParams(**params)\n",
    "\n",
    "            model = roleR.runRole(roleR.roleModel(p))\n",
    "            stats = roleR.getSumStats(model)\n",
    "            \n",
    "            stats_df = pandas2ri.rpy2py(stats)\n",
    "            stats_df = stats_df[[col for col in stats_df.columns if col in self.columns]]\n",
    "            stats_df = stats_df.dropna()\n",
    "            \n",
    "            # print(np.array(stats_df).shape)\n",
    "            arr.append(torch.Tensor(np.array(stats_df)))\n",
    "        return arr\n",
    "            \n",
    "\n",
    "theta_samples = prior.get_joint_uniform().sample((200,))\n",
    "simulator = Simulator(prior=prior, columns=[\"richness\", \"hill_abund_1\", \"hill_abund_2\", \"hill_abund_3\", \"hill_abund_4\", \"hill_trait_1\", \"hill_trait_2\", \"hill_trait_3\", \"hill_trait_4\"])\n",
    "\n",
    "x_samples = simulator.simulate(theta_samples)\n",
    "\n",
    "# x_samples_shape = x_samples.shape\n",
    "# x_samples = x_samples.reshape(x_samples_shape[0] * x_samples_shape[1], x_samples_shape[2])\n",
    "# theta_samples = np.repeat(theta_samples, x_samples_shape[1])\n",
    "# print(x_samples.shape, theta_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([39933, 9]) torch.Size([39933, 2])\n"
     ]
    }
   ],
   "source": [
    "x_samples_transformed = torch.tensor([])\n",
    "theta_samples_transformed = torch.tensor([])\n",
    "\n",
    "for x, theta in zip(x_samples, theta_samples):\n",
    "    x_samples_transformed = torch.cat((x_samples_transformed, x))\n",
    "    theta_samples_transformed = torch.cat((theta_samples_transformed, torch.tile(theta, (x.shape[0], 1))))\n",
    "    \n",
    "print(x_samples_transformed.shape, theta_samples_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sbi.inference import SNPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 216 epochs."
     ]
    }
   ],
   "source": [
    "snpe = SNPE(prior=prior.get_joint_uniform())\n",
    "\n",
    "density_estimator = snpe.append_simulations(theta_samples_transformed, x_samples_transformed).train()\n",
    "\n",
    "posterior = snpe.build_posterior(density_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[100.1724, 490.1338]])\n",
      "Observed simulation output: tensor([16.5849, 12.4378, 10.4587,  9.3509, 16.3699, 12.3007, 10.5423,  9.6749,\n",
      "        25.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Drawing 1000 posterior samples: 1091it [00:00, 184478.36it/s]           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior samples shape: torch.Size([1000, 2])\n",
      "Posterior mean estimate: tensor([106.0260, 689.8876])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "theta_obs = prior.get_joint_uniform().sample((1,))  # (this is the true but unknown parameter)\n",
    "print(theta_obs)\n",
    "x_obs = simulator.simulate(theta_obs)[-1][-1]\n",
    "print(\"Observed simulation output:\", x_obs)\n",
    "\n",
    "# Use the learned posterior to sample inferred parameters given the observed output\n",
    "posterior_samples = posterior.sample((1000,), x=x_obs)\n",
    "print(\"Posterior samples shape:\", posterior_samples.shape)\n",
    "\n",
    "# # Compute a point estimate (e.g. the posterior mean)\n",
    "posterior_mean = posterior_samples.mean(dim=0)\n",
    "print(\"Posterior mean estimate:\", posterior_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prior = {\n",
    "#     \"individuals_local\": int,\n",
    "#     \"individuals_meta\": int,\n",
    "#     \"species_meta\": int,\n",
    "#     \"speciation_local\": float,\n",
    "#     \"speciation_meta\": float,\n",
    "#     \"extinction_meta\": float,\n",
    "#     \"env_sigma\": float,\n",
    "#     \"trait_sigma\": float,\n",
    "#     \"comp_sigma\": float,\n",
    "#     \"dispersal_prob\": float,\n",
    "#     \"mutation_rate\": float,\n",
    "#     \"equilib_escape\": int,\n",
    "#     \"num_basepairs\": int,\n",
    "#     \"init_type\": str,\n",
    "#     \"niter\": int,\n",
    "#     \"niterTimestep\": int,\n",
    "# }\n",
    "\n",
    "# torch\n",
    "# human readable discrete\n",
    "\n",
    "# generate dataset\n",
    "\n",
    "# class ChoiceDistribution(Distribution):\n",
    "#     def __init__(self, choices: list):\n",
    "#         super().__init__(0, len(choices))  # Initialize base class\n",
    "#         self.choices = choices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.1428e+02, 3.9715e+03, 3.5400e+01, 1.5399e-01, 7.8941e-01, 6.8638e-01,\n",
      "        3.3611e+00, 1.2061e-01, 9.6169e+00, 6.3239e-01, 4.6293e-08, 9.7214e+01,\n",
      "        5.8275e+03])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.distributions import Uniform\n",
    "\n",
    "\n",
    "\n",
    "# Lower bounds for the 15 numeric parameters (order unchanged):\n",
    "prior_low = torch.tensor([\n",
    "    50.0,        # individuals_local (J): local community individuals\n",
    "    1000.0,      # individuals_meta (JM): metacommunity individuals\n",
    "    20.0,        # species_meta (SM): metacommunity species richness\n",
    "    0.0,         # speciation_local (ν): local speciation rate in [0,1]\n",
    "    0.001,       # speciation_meta (Λ): metacommunity speciation rate\n",
    "    0.0,         # extinction_meta (Ε): extinction rate in [0,1]\n",
    "    0.01,        # env_sigma: metacommunity trait evolution variance (σ²)\n",
    "    0.01,        # trait_sigma: local trait evolution variance (σ²)\n",
    "    0.1,         # comp_sigma: strength of ecological filtering (SE)\n",
    "    0.0,         # dispersal_prob (m): immigration rate from metacommunity in [0,1]\n",
    "    1e-9,        # mutation_rate (µ): mutation rate\n",
    "    1.0,         # equilib_escape (α): abundance/Ne scaling factor\n",
    "    100.0,       # num_basepairs (L): sequence length (bp)\n",
    "])\n",
    "\n",
    "# Upper bounds for the 15 numeric parameters:\n",
    "prior_high = torch.tensor([\n",
    "    1000.0,      # individuals_local (J)\n",
    "    10000.0,     # individuals_meta (JM)\n",
    "    80.0,        # species_meta (SM)\n",
    "    1.0,         # speciation_local (ν)\n",
    "    1.0,         # speciation_meta (Λ)\n",
    "    1.0,         # extinction_meta (Ε)\n",
    "    5.0,         # env_sigma (σ² metacommunity)\n",
    "    5.0,         # trait_sigma (σ² local)\n",
    "    10.0,        # comp_sigma (SE)\n",
    "    1.0,         # dispersal_prob (m)\n",
    "    1e-6,        # mutation_rate (µ)\n",
    "    100.0,       # equilib_escape (α)\n",
    "    10000.0,     # num_basepairs (L)\n",
    "])\n",
    "\n",
    "# Create the joint uniform prior over these 15 parameters.\n",
    "joint_prior = Uniform(low=prior_low, high=prior_high)\n",
    "\n",
    "# Example: Draw 5 samples from this joint prior.\n",
    "samples = joint_prior.sample()\n",
    "print(samples)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
