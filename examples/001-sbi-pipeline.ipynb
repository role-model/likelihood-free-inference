{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Role R Likelihood-free Simulation Based Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/micahtilton/Documents/GitHub/likelihood-free-inference/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from roler.model import ModelPrior\n",
    "from roler.distributions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = ModelPrior(\n",
    "    individuals_local=IntDistribution(50, 300),\n",
    "    individuals_meta=IntDistribution(400, 1000),\n",
    "    species_meta=50,\n",
    "    speciation_local=0.05,\n",
    "    speciation_meta=0.05,\n",
    "    extinction_meta=0.05,\n",
    "    env_sigma=0.5,\n",
    "    trait_sigma=1,\n",
    "    comp_sigma=0.5,\n",
    "    dispersal_prob=0.1,\n",
    "    mutation_rate=0.01,\n",
    "    equilib_escape=1,\n",
    "    num_basepairs=250,\n",
    "    init_type='oceanic_island',\n",
    "    niter=2000,\n",
    "    niterTimestep=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a Dataset of Simulations\n",
    "\n",
    "This cell generates a dataset of simulation results using the `Dataset` class. It initializes a `Dataset` object with the previously defined `simulator` and `prior`. The `generate_dataset` method is then called to generate `samples=10` simulation runs. The resulting parameter values (`theta`) and summary statistics (`x`) are stored. Finally, the shapes of `theta` and `x` are printed to show the dimensions of the generated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing the 'roleR' R package from GitHub...\n",
      "Installing the 'roleR' R package from GitHub...\n",
      "Installing the 'roleR' R package from GitHub...\n",
      "Installing the 'roleR' R package from GitHub...\n",
      "Installing the 'roleR' R package from GitHub...\n",
      "Installing the 'roleR' R package from GitHub...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using GitHub PAT from the git credential store.\n",
      "\n",
      "R[write to console]: Using GitHub PAT from the git credential store.\n",
      "\n",
      "R[write to console]: Using GitHub PAT from the git credential store.\n",
      "\n",
      "R[write to console]: Using GitHub PAT from the git credential store.\n",
      "\n",
      "R[write to console]: Using GitHub PAT from the git credential store.\n",
      "\n",
      "R[write to console]: Using GitHub PAT from the git credential store.\n",
      "\n",
      "R[write to console]: Skipping install of 'roleR' from a github remote, the SHA1 (cc6546a1) has not changed since last install.\n",
      "  Use `force = TRUE` to force installation\n",
      "\n",
      "R[write to console]: Skipping install of 'roleR' from a github remote, the SHA1 (cc6546a1) has not changed since last install.\n",
      "  Use `force = TRUE` to force installation\n",
      "\n",
      "R[write to console]: Skipping install of 'roleR' from a github remote, the SHA1 (cc6546a1) has not changed since last install.\n",
      "  Use `force = TRUE` to force installation\n",
      "\n",
      "R[write to console]: Skipping install of 'roleR' from a github remote, the SHA1 (cc6546a1) has not changed since last install.\n",
      "  Use `force = TRUE` to force installation\n",
      "\n",
      "R[write to console]: Skipping install of 'roleR' from a github remote, the SHA1 (cc6546a1) has not changed since last install.\n",
      "  Use `force = TRUE` to force installation\n",
      "\n",
      "R[write to console]: Skipping install of 'roleR' from a github remote, the SHA1 (cc6546a1) has not changed since last install.\n",
      "  Use `force = TRUE` to force installation\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta.size torch.Size([3193, 2])\n",
      "x.size torch.Size([3193, 9])\n"
     ]
    }
   ],
   "source": [
    "from roler.datasets import Dataset\n",
    "from roler.simulation import Simulator\n",
    "\n",
    "simulator = Simulator()\n",
    "dataset = Dataset(simulator=simulator, prior=prior)\n",
    "theta, x = dataset.generate_dataset(samples=16, n_jobs=16)\n",
    "\n",
    "print(\"theta.size\", theta.shape)\n",
    "print(\"x.size\", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Inference with SNPE (Sequential Neural Posterior Estimation)\n",
    "\n",
    "This cell uses the `sbi` library to perform inference and estimate the posterior distribution of the model parameters given the simulated data.\n",
    "\n",
    "1.  An `SNPE` object is initialized using the joint uniform prior obtained from `prior.get_joint_uniform()`.\n",
    "2.  The simulated parameter values (`theta`) and summary statistics (`x`) generated in the previous cell are used to train a neural density estimator using `snpe.append_simulations(theta, x).train()`.\n",
    "3.  A posterior object is built from the trained density estimator using `snpe.build_posterior(density_estimator)`. This posterior object can then be used to sample from the approximate posterior distribution or evaluate its density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural network successfully converged after 306 epochs."
     ]
    }
   ],
   "source": [
    "from sbi.inference import SNPE\n",
    "\n",
    "snpe = SNPE(prior=prior.get_joint_uniform())\n",
    "density_estimator = snpe.append_simulations(theta, x).train()\n",
    "posterior = snpe.build_posterior(density_estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Learned Posterior with Observed Data\n",
    "\n",
    "This cell evaluates the performance of the learned posterior by:\n",
    "\n",
    "1.  Generating a single \"observed\" dataset point `x_obs` with corresponding true parameter values `theta_true` using `dataset.generate_dataset(samples=1)`.\n",
    "2.  Sampling from the posterior distribution conditioned on the observed data `x_obs` using `posterior.sample((1000,), x=x_obs)`, creating 1000 posterior samples.\n",
    "3.  Computing the posterior mean as a point estimate of the parameters.\n",
    "4.  Printing the true parameter values (`theta_true`) and the posterior mean estimate for comparison. This allows you to assess how well the inference procedure recovers the true parameters given the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed simulation output: tensor([20.0746, 11.7891,  8.5310,  7.0830, 22.8605, 14.9112, 11.7992, 10.3749,\n",
      "        41.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Drawing 1000 posterior samples: 100%|██████████| 1000/1000 [00:00<00:00, 165481.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior samples shape: torch.Size([1000, 2])\n",
      "Posterior mean estimate: tensor([220.7415, 686.4638])\n",
      "\n",
      "Theta True      : tensor([232.5207, 524.2098])\n",
      "Theta Prediction: tensor([220.7415, 686.4638])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "theta_true, x_obs = dataset.generate_dataset(samples=1)\n",
    "theta_true, x_obs = theta_true[-1], x_obs[-1]\n",
    "print(\"Observed simulation output:\", x_obs)\n",
    "\n",
    "# Use the learned posterior to sample inferred parameters given the observed output\n",
    "posterior_samples = posterior.sample((1000,), x=x_obs)\n",
    "print(\"Posterior samples shape:\", posterior_samples.shape)\n",
    "\n",
    "# Compute a point estimate (e.g. the posterior mean)\n",
    "posterior_mean = posterior_samples.mean(dim=0)\n",
    "print(\"Posterior mean estimate:\", posterior_mean)\n",
    "\n",
    "print()\n",
    "print(\"Theta True      :\", theta_true)\n",
    "print(\"Theta Prediction:\", posterior_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True       : ModelParams(individuals_local=233, individuals_meta=524, species_meta=50, speciation_local=0.05, speciation_meta=0.05, extinction_meta=0.05, env_sigma=0.5, trait_sigma=1, comp_sigma=0.5, dispersal_prob=0.1, mutation_rate=0.01, equilib_escape=1, num_basepairs=250, init_type='oceanic_island', niter=2000, niterTimestep=10)\n",
      "Prediction : ModelParams(individuals_local=221, individuals_meta=686, species_meta=50, speciation_local=0.05, speciation_meta=0.05, extinction_meta=0.05, env_sigma=0.5, trait_sigma=1, comp_sigma=0.5, dispersal_prob=0.1, mutation_rate=0.01, equilib_escape=1, num_basepairs=250, init_type='oceanic_island', niter=2000, niterTimestep=10)\n"
     ]
    }
   ],
   "source": [
    "print(\"True       :\", dataset.get_params_from_tensor(theta_true))\n",
    "print(\"Prediction :\", dataset.get_params_from_tensor(posterior_mean))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
